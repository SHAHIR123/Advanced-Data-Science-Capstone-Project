{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# APS SYSTEM FAILURE PREDICTION IN SCANIA TRUCKS", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "The data set consists of data collected from heavy Scania trucks in everyday usage. The system in focus is the Air Pressure system (APS) which generates pressurized air that is utilized in various functions in a truck, such as braking and gear changes. The data sets' positive class consists of component failures for a specific component of the APS system. The negative class consists of trucks with failures for components not related to the APS. The data consists of a subset of all available data, selected by experts. The training set contains 60000 examples in total in which 59000 belong to the negative class and 1000 positive class. The test set contains 16000 examples. There are 171 attributes per record. It was imported from the UCI ML Repository https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/00421/aps_failure_training_set.csv\n! wget https://archive.ics.uci.edu/ml/machine-learning-databases/00421/aps_failure_test_set.csv"
        }, 
        {
            "source": "# Deep Learning Model with Keras Library", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Results: 99.17% (0.08%)\n"
                }
            ], 
            "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n% matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom keras.preprocessing import sequence\nfrom keras.models import load_model\nfrom keras.layers import Dense\nfrom keras.layers import Input, LSTM\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n\ntrain = pd.read_csv(\"aps_failure_training_set.csv\", skiprows=20)\ntest = pd.read_csv(\"aps_failure_test_set.csv\", skiprows=20)\n\n\ndef pre_process(df):\n    df.replace('na', np.nan, inplace = True)\n    df.fillna(0, inplace = True)\n    #Get result field out and replace neg with 0 and pos with 1\n    result = df[\"class\"]\n    df3 = result.replace('neg',0,inplace = True)\n    df4 = result.replace('pos',1,inplace = True)\n    df_numeric = df.astype(float)\n    return df_numeric\n\n\n\ndf = pre_process(train)\ntest_df = pre_process(test)\n\nX = df.drop(\"class\", axis=1)\nY = df[\"class\"]\n\nX_test = test_df.drop(\"class\", axis=1)\nY_test = test_df[\"class\"]\n\n\nbatch_size = 64\nepochs = 120\n\n# Baseline model for the neural network. We choose a hidden layer of 10 neurons. The lesser number of neurons helps to eliminate the redundancies in the data and select the more important features.\ndef create_baseline():\n    # create model\n    model = Sequential()\n    model.add(Dense(10, input_dim=170, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n    #compile model. We use the logarithmic loss function, and the Adam gradient optimizer.\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\n# Evaluate model using standardized dataset. \nestimators = []\nestimators.append(('standardize', StandardScaler()))\nestimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=epochs, batch_size=batch_size, verbose=0)))\npipeline = Pipeline(estimators)\nkfold = StratifiedKFold(n_splits=10, shuffle=True)\nresults = cross_val_score(pipeline, X, Y, cv=kfold)\nprint(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n\n"
        }, 
        {
            "source": "## Fit model on training set to predict the test set", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "accuracy of the model on test data set: 98.98% \n"
                }
            ], 
            "source": "prediction = pipeline.fit(X, Y)\n\ntest_prediction = pipeline.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(Y_test, test_prediction)\nprint(\"accuracy of the model on test data set: %.2f%% \" % (accuracy.mean()*100))\n\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}